{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Busca Semântica com Similaridade do Cosseno\n",
        "\n",
        "Notebook 3 da série: mostra como implementar uma busca vetorial simples usando cosine similarity para priorizar documentos de acordo com o ângulo entre embeddings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Introdução\n",
        "- **Busca semântica** encontra conteúdo relevante mesmo quando a consulta não compartilha termos exatos.\n",
        "- **Busca literal x vetorial:** literal usa palavras-chave; vetorial compara embeddings (significado) e é robusta a sinônimos/paráfrases.\n",
        "- **Cosine similarity** é a técnica mais comum porque normaliza vetores e foca no ângulo, ideal para textos de tamanhos diferentes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Mini teoria\n",
        "- **Fórmula:** `cos(a, b) = (a · b) / (||a|| * ||b||)`.\n",
        "- **Normalização:** dividir cada vetor pela sua norma garante que apenas a direção (ângulo) importe.\n",
        "- **Por que ângulo > magnitude?** Textos longos podem gerar embeddings com norma maior; cosine corrige esse efeito e privilegia alinhamento semântico.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualização dos ângulos\n",
        "A ilustração abaixo mostra, em 2D, como vetores com ângulos pequenos (menor que 30°) têm cosine alto, enquanto ângulos maiores indicam menor similaridade.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(11)\n",
        "plt.style.use(\"seaborn-v0_8\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base = np.array([1.0, 0.0])\n",
        "angles_deg = [0, 20, 60, 120]\n",
        "colors = [\"#4E79A7\", \"#F28E2B\", \"#E15759\", \"#76B7B2\"]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "ax.quiver(0, 0, base[0], base[1], angles='xy', scale_units='xy', scale=1, color=\"#4E79A7\", label=\"Consulta\")\n",
        "\n",
        "for angle, color in zip(angles_deg, colors):\n",
        "    rad = np.deg2rad(angle)\n",
        "    vec = np.array([np.cos(rad), np.sin(rad)])\n",
        "    ax.quiver(0, 0, vec[0], vec[1], angles='xy', scale_units='xy', scale=1, color=color, label=f\"Doc {angle}°\")\n",
        "\n",
        "ax.set_xlim(-1.1, 1.2)\n",
        "ax.set_ylim(-1.1, 1.2)\n",
        "ax.set_aspect('equal')\n",
        "ax.axhline(0, color='gray', linewidth=0.5)\n",
        "ax.axvline(0, color='gray', linewidth=0.5)\n",
        "ax.set_title(\"Ângulos e Similaridade do Cosseno\")\n",
        "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Demonstração prática\n",
        "Vamos criar 5 textos curtos e gerar embeddings simulados (dimensão 4). Em um projeto real usaríamos `sentence-transformers`, mas aqui manteremos simples para focar no cálculo da similaridade.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "documents = [\n",
        "    \"Guia rápido de cultivo de café orgânico em casa\",\n",
        "    \"Receitas de sobremesas com chocolate amargo\",\n",
        "    \"Como escolher o melhor grão para espresso intenso\",\n",
        "    \"Cuidados essenciais ao torrar café em pequena escala\",\n",
        "    \"Variações de bebidas geladas à base de café\"\n",
        "]\n",
        "\n",
        "queries = [\n",
        "    \"Qual o melhor grão para espresso?\",\n",
        "    \"Como fazer sobremesa com chocolate?\"\n",
        "]\n",
        "\n",
        "# Embeddings sintéticos (apenas para demonstração)\n",
        "emb_dim = 4\n",
        "doc_embeddings = np.abs(np.random.randn(len(documents), emb_dim))\n",
        "query_embeddings = np.abs(np.random.randn(len(queries), emb_dim))\n",
        "\n",
        "docs_df = pd.DataFrame(doc_embeddings, columns=[f\"dim_{i+1}\" for i in range(emb_dim)])\n",
        "docs_df.insert(0, \"documento\", documents)\n",
        "queries_df = pd.DataFrame(query_embeddings, columns=[f\"dim_{i+1}\" for i in range(emb_dim)])\n",
        "queries_df.insert(0, \"consulta\", queries)\n",
        "\n",
        "docs_df, queries_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Implementação Python\n",
        "Passos: (1) normalizar embeddings, (2) calcular cosine similarity manualmente, (3) criar função de busca.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_rows(matrix: np.ndarray) -> np.ndarray:\n",
        "    norms = np.linalg.norm(matrix, axis=1, keepdims=True)\n",
        "    norms[norms == 0] = 1e-9\n",
        "    return matrix / norms\n",
        "\n",
        "\n",
        "norm_docs = normalize_rows(doc_embeddings)\n",
        "norm_queries = normalize_rows(query_embeddings)\n",
        "\n",
        "norm_docs[:2], norm_queries[:1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cosine_similarity_matrix(query_matrix: np.ndarray, doc_matrix: np.ndarray) -> np.ndarray:\n",
        "    return query_matrix @ doc_matrix.T\n",
        "\n",
        "\n",
        "similarity = cosine_similarity_matrix(norm_queries, norm_docs)\n",
        "similarity_df = pd.DataFrame(similarity, index=queries, columns=documents)\n",
        "similarity_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search(query_idx: int, top_k: int = 3) -> pd.DataFrame:\n",
        "    sims = similarity[query_idx]\n",
        "    ranking = (\n",
        "        pd.DataFrame({\"documento\": documents, \"cosine_similarity\": sims})\n",
        "        .sort_values(by=\"cosine_similarity\", ascending=False)\n",
        "        .head(top_k)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    ranking.insert(0, \"consulta\", queries[query_idx])\n",
        "    return ranking\n",
        "\n",
        "search(0, top_k=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for idx in range(len(queries)):\n",
        "    display(search(idx, top_k=3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "sns.heatmap(similarity_df, annot=True, cmap=\"YlGnBu\", fmt=\".2f\")\n",
        "plt.title(\"Heatmap de Similaridade (Cosine)\")\n",
        "plt.ylabel(\"Consultas\")\n",
        "plt.xlabel(\"Documentos\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Interpretação:** valores próximos de 1 indicam alto alinhamento semântico entre consulta e documento. Como normalizamos os vetores, textos longos não dominam o ranking apenas pelo tamanho.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Simulação pgvector (SQL)\n",
        "Exemplo de como salvar embeddings e consultar usando cosine similarity no Postgres com pgvector.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```sql\n",
        "-- 1. Tabela para mensagens / documentos\n",
        "CREATE TABLE kb_messages (\n",
        "    id SERIAL PRIMARY KEY,\n",
        "    titulo TEXT,\n",
        "    conteudo TEXT,\n",
        "    embedding vector(768)\n",
        ");\n",
        "\n",
        "-- 2. Índice HNSW para cosine (vector_cosine_ops)\n",
        "CREATE INDEX kb_messages_embedding_hnsw\n",
        "ON kb_messages\n",
        "USING hnsw (embedding vector_cosine_ops);\n",
        "\n",
        "-- 3. Query de busca semântica usando operador <=> (cosine distance)\n",
        "WITH query AS (\n",
        "  SELECT '[0.12, 0.03, ..., 0.05]'::vector AS embedding -- embedding gerado na aplicação\n",
        ")\n",
        "SELECT m.id, m.titulo, m.embedding <=> query.embedding AS distance\n",
        "FROM kb_messages m, query\n",
        "ORDER BY distance ASC\n",
        "LIMIT 5;\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Como escalar\n",
        "- **Chunking de texto:** divida documentos longos em partes menores (ex.: 500 palavras) para melhorar recall.\n",
        "- **Dimensão dos vetores:** modelos maiores (768, 1024, 1536+) capturam mais nuance, mas aumentam custo.\n",
        "- **Tamanho do banco:** escolha índices ANN adequados (IVFFlat/HNSW); monitore `lists`, `ef_search`.\n",
        "- **Re-ranking:** após a busca vetorial, reordene com modelos menores (ex.: cross-encoder) ou sinais adicionais (popularidade, data).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exemplo simples de chunking\n",
        "```text\n",
        "Documento longo → [parágrafo 1], [parágrafo 2], ...\n",
        "Cada chunk recebe um embedding próprio e herda metadados (ID do documento, seção, etc.).\n",
        "Na busca, retornamos o chunk mais relevante e opcionalmente agregamos ao documento original.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Conclusão\n",
        "- Cosine similarity padroniza comparações entre textos de tamanhos distintos.\n",
        "- Busca semântica melhora experiências de FAQ, suporte, documentação e discovery.\n",
        "- pgvector oferece operador `<=>` e índices ANN otimizados para cosine.\n",
        "- Próximo notebook: distância euclidiana aplicada a agrupamentos e restrições rígidas.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
